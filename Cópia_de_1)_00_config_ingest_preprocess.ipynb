{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CheilaBaiao/GEE_SR/blob/main/C%C3%B3pia_de_1)_00_config_ingest_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDALSz7qMVKF"
      },
      "outputs": [],
      "source": [
        "# @title Setup (por aluno/ano): instalar libs, montar Drive e configurar projeto (rodar 1x por sessão)\n",
        "# @title Setup (por aluno/ano): instalar libs, montar Drive e configurar projeto (rodar 1x por sessão)\n",
        "# Instalações essenciais (evite repetir em outras células)\n",
        "# @title Setup (por aluno/ano): instalar libs, montar Drive e configurar projeto (rodar 1x por sessão)\n",
        "# Instalações essenciais (evite repetir em outras células)\n",
        "%pip -q install numpy pandas geopandas shapely pyproj rasterio rioxarray xarray tqdm pyyaml joblib earthengine-api\n",
        "\n",
        "# Imports base\n",
        "import os, json, time, glob, math, gc, warnings, yaml, re\n",
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import box\n",
        "\n",
        "# Montar Google Drive (Colab)\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except Exception as e:\n",
        "    print(\"Aviso ao montar Drive:\", e)\n",
        "\n",
        "# ---------- PARÂMETROS POR ALUNO ----------\n",
        "# → Cada aluno edita SOMENTE estes campos:\n",
        "SINGLE_YEAR     = 2015          # <<< ANO que ESTE aluno ficará responsável\n",
        "CALENDAR        = \"bimonthly\"   # \"bimonthly\" (usa meses 1,3,5,7,9,11) ou \"monthly\"\n",
        "\n",
        "# Escolha dos meses (subconjunto) — MAIS RÁPIDO:\n",
        "# Para CALENDAR=\"bimonthly\": escolha entre [1,3,5,7,9,11]\n",
        "# Para CALENDAR=\"monthly\":   escolha entre [1..12]\n",
        "SELECT_MONTHS   = [1, 3, 5]     # <<< edite os meses desejados (ex.: [1,3,5] = jan/mar/mai)\n",
        "\n",
        "# (Opcional) Você pode especificar exatamente os YYYYMM, ignorando SELECT_MONTHS:\n",
        "#EXACT_YYYYMM    = [\"201501\",\"201503\",\"201505\"]  # <<< preencha ou deixe None\n",
        "EXACT_YYYYMM    = None\n",
        "\n",
        "# Sufixo de checkpoint (apenas por ano; simples e suficiente)\n",
        "CKP_SUFFIX = f\"{SINGLE_YEAR}\"\n",
        "\n",
        "# --- PASTAS DO PROJETO ---\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/Pantanal_TippingPoints/index\")\n",
        "RAW_DIR  = BASE_DIR / \"raw\"\n",
        "INT_DIR  = BASE_DIR / \"interim\"\n",
        "OUT_DIR  = BASE_DIR / \"outputs\"\n",
        "LOG_DIR  = BASE_DIR / \"logs\" / CKP_SUFFIX   # logs segregados por ANO\n",
        "for d in (RAW_DIR, INT_DIR, OUT_DIR, LOG_DIR): d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- CONFIG ÚNICA ---\n",
        "CONFIG = {\n",
        "    \"calendar\": CALENDAR,                 # \"monthly\" ou \"bimonthly\"\n",
        "    \"years\": [int(SINGLE_YEAR)],          # fixo: um ano por aluno\n",
        "    \"only_months\": None,                  # (não usamos; deixado por compatibilidade)\n",
        "\n",
        "    # Projeção/escala\n",
        "    \"crs_epsg\": 31983,                    # SIRGAS 2000 / UTM 23S\n",
        "    \"optical_pixel_m\": 30,\n",
        "    \"agg_optical_to_m\": 300,\n",
        "\n",
        "    # Máscaras / NoData\n",
        "    \"nodata\": -32768,\n",
        "    \"mask_water_threshold\": 0.05,\n",
        "    \"min_obs_hint\": 2,\n",
        "\n",
        "    # Janela flex (DJFM mais larga)\n",
        "    \"wet_months\": [12, 1, 2, 3],\n",
        "    \"wet_window_months\": 4,\n",
        "    \"dry_window_months\": 2,\n",
        "\n",
        "    # Flags\n",
        "    \"resume\": True,\n",
        "\n",
        "    # Assets\n",
        "    \"ee_assets\": {\n",
        "        \"landsat_collections\": {\n",
        "            \"L5_SR\": \"LANDSAT/LT05/C02/T1_L2\",\n",
        "            \"L7_SR\": \"LANDSAT/LE07/C02/T1_L2\",\n",
        "            \"L8_SR\": \"LANDSAT/LC08/C02/T1_L2\",\n",
        "            \"L9_SR\": \"LANDSAT/LC09/C02/T1_L2\"\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # Caminho do limite no Drive\n",
        "    \"boundary_path\": \"/content/drive/MyDrive/Pantanal_TippingPoints/Pantanal.shp\",\n",
        "\n",
        "    # Pastas de export no Drive\n",
        "    \"gee_drive_folder_optical\": \"Pantanal_TippingPoints_optical\"\n",
        "}\n",
        "\n",
        "# Helpers genéricos\n",
        "def log(msg):\n",
        "    print(time.strftime(\"[%Y-%m-%d %H:%M:%S]\"), msg)\n",
        "\n",
        "def _validate_months(calendar, months):\n",
        "    months = sorted(list(dict.fromkeys(int(m) for m in months)))\n",
        "    if calendar == \"bimonthly\":\n",
        "        allowed = {1,3,5,7,9,11}\n",
        "        bad = [m for m in months if m not in allowed]\n",
        "        assert not bad, f\"Meses inválidos para 'bimonthly': {bad}. Use apenas {sorted(allowed)}.\"\n",
        "    else:\n",
        "        allowed = set(range(1,13))\n",
        "        bad = [m for m in months if m not in allowed]\n",
        "        assert not bad, f\"Meses inválidos para 'monthly': {bad}. Use 1..12.\"\n",
        "    return months\n",
        "\n",
        "def build_time_slices(year:int, calendar:str, select_months=None, exact_yyyymm=None):\n",
        "    \"\"\"Constroi lista de YYYYMM conforme seleção.\"\"\"\n",
        "    if exact_yyyymm:\n",
        "        # Sanidade: manter apenas entradas do ano escolhido\n",
        "        y = str(year)\n",
        "        yms = [str(s) for s in exact_yyyymm]\n",
        "        yms = [s for s in yms if len(s)==6 and s.startswith(y)]\n",
        "        assert yms, \"EXACT_YYYYMM fornecido não contém períodos válidos deste ano.\"\n",
        "        return sorted(yms)\n",
        "    # Caso geral: meses do ano escolhido\n",
        "    if select_months is None or len(select_months)==0:\n",
        "        # todos os meses do calendário\n",
        "        months = [1,3,5,7,9,11] if calendar==\"bimonthly\" else list(range(1,13))\n",
        "    else:\n",
        "        months = _validate_months(calendar, select_months)\n",
        "    return [f\"{year}{m:02d}\" for m in months]\n",
        "\n",
        "# >>> períodos-alvo deste aluno (ANO + subconjunto de meses)\n",
        "TIME_SLICES = build_time_slices(SINGLE_YEAR, CALENDAR, SELECT_MONTHS, EXACT_YYYYMM)\n",
        "print(\"Períodos-alvo (este aluno):\", TIME_SLICES)\n",
        "print(f\"Checkpoints serão salvos em: {LOG_DIR}\")\n",
        "\n",
        "assert len(TIME_SLICES) > 0, "Nenhum período selecionado. Verifique SELECT_MONTHS/EXACT_YYYYMM."
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dkPxMBlMf2Y"
      },
      "outputs": [],
      "source": [
        "# @title Célula 2 — GEE init, período flex (DJFM) e utilitários\n",
        "\n",
        "import ee, datetime, time\n",
        "\n",
        "# --- Inicialização do GEE ---\n",
        "try:\n",
        "    ee.Initialize(project=\"ee-cheilabaiao\")\n",
        "    print(\"✔ GEE já autenticado.\")\n",
        "except Exception:\n",
        "    print(\"⇢ Autenticando no GEE…\")\n",
        "    ee.Authenticate()          # siga o link e cole o token\n",
        "    ee.Initialize()\n",
        "    print(\"✔ GEE autenticado.\")\n",
        "\n",
        "def period_for_yyyymm(yyyymm: str):\n",
        "    \"\"\"\n",
        "    Retorna (start, end) como ee.Date, aplicando janela 'flex':\n",
        "      - Meses úmidos (CONFIG['wet_months']): avanço de CONFIG['wet_window_months'] meses\n",
        "      - Demais meses: avanço de CONFIG['dry_window_months'] meses\n",
        "    \"\"\"\n",
        "    y = int(yyyymm[:4]); m = int(yyyymm[4:6])\n",
        "    start = ee.Date.fromYMD(y, m, 1)\n",
        "    if m in CONFIG[\"wet_months\"]:\n",
        "        end = start.advance(CONFIG[\"wet_window_months\"], 'month')\n",
        "    else:\n",
        "        end = start.advance(CONFIG[\"dry_window_months\"], 'month')\n",
        "    return start, end\n",
        "\n",
        "def log(msg):  # reforço local (caso não esteja no escopo)\n",
        "    print(time.strftime(\"[%Y-%m-%d %H:%M:%S]\"), msg)\n",
        "\n",
        "def ee_wait_tasks(task_list, sleep_s=10):\n",
        "    \"\"\"Acompanha várias tasks do GEE até concluírem, com log simples.\"\"\"\n",
        "    pending = {t.id: t for t in task_list}\n",
        "    last_state = {}\n",
        "    while pending:\n",
        "        done = []\n",
        "        for tid, t in pending.items():\n",
        "            st = t.status()\n",
        "            state = st.get('state','UNKNOWN')\n",
        "            if last_state.get(tid) != state:\n",
        "                log(f\"Tarefa {tid[:6]}: {state}\")\n",
        "                last_state[tid] = state\n",
        "            if state in (\"COMPLETED\",\"CANCELLED\",\"FAILED\"):\n",
        "                done.append(tid)\n",
        "        for tid in done:\n",
        "            pending.pop(tid, None)\n",
        "        if pending:\n",
        "            time.sleep(sleep_s)\n",
        "    log(\"✔ Todas as tarefas finalizaram.\")\n",
        "\n",
        "# --- (Opcional) Debug rápido: contar cenas por sensor num período ---\n",
        "def debug_count_scenes(yyyymm: str, region_geom):\n",
        "    start, end = period_for_yyyymm(yyyymm)\n",
        "    assets = CONFIG[\"ee_assets\"][\"landsat_collections\"]\n",
        "    counts = {}\n",
        "    for key, col in assets.items():\n",
        "        n = (ee.ImageCollection(col)\n",
        "             .filterDate(start, end)\n",
        "             .filterBounds(region_geom)\n",
        "             .size())\n",
        "        counts[key] = n.getInfo()\n",
        "    print(f\"[DEBUG] {yyyymm} — L5:{counts.get('L5_SR',0)}  L7:{counts.get('L7_SR',0)}  \"\n",
        "          f\"L8:{counts.get('L8_SR',0)}  L9:{counts.get('L9_SR',0)}\")\n",
        "\n",
        "print(\"✔ Célula 2 pronta: GEE, janela flex e utilitários carregados.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iARplt5MylR"
      },
      "outputs": [],
      "source": [
        "# @title Célula 3 — Carregar boundary do Drive → ee.Geometry (pant) e pant_simpl\n",
        "import json\n",
        "from pathlib import Path\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import MultiPolygon, Polygon\n",
        "from shapely.ops import unary_union\n",
        "\n",
        "# (opcional) parâmetro de tolerância para a simplificação (em metros no CRS do projeto)\n",
        "SIMPLIFY_TOL_M = 500  # ajuste se quiser; 300–1000 m costuma ir bem para region\n",
        "\n",
        "bpath = Path(CONFIG[\"boundary_path\"])\n",
        "assert bpath.exists(), f\"Limite não encontrado: {bpath}. Ajuste CONFIG['boundary_path'].\"\n",
        "\n",
        "# 1) Ler e normalizar\n",
        "gdf = gpd.read_file(bpath)\n",
        "assert len(gdf), f\"Nenhuma feição encontrada em {bpath}\"\n",
        "\n",
        "# Corrige geometrias inválidas (buffer(0)) e remove vazios\n",
        "gdf[\"geometry\"] = gdf[\"geometry\"].buffer(0)\n",
        "gdf = gdf[~gdf.geometry.is_empty & gdf.geometry.notnull()].copy()\n",
        "assert len(gdf), \"Todas as geometrias ficaram vazias após correção.\"\n",
        "\n",
        "# 2) Dissolver em um único polígono\n",
        "if \"name\" in gdf.columns:\n",
        "    gdf_diss = gdf.dissolve()\n",
        "else:\n",
        "    gdf[\"_ones_\"] = 1\n",
        "    gdf_diss = gdf.dissolve(\"_ones_\").drop(columns=\"_ones_\", errors=\"ignore\")\n",
        "\n",
        "geom_proj = gdf_diss.geometry.values[0]\n",
        "assert geom_proj.is_valid and not geom_proj.is_empty, \"Geometry inválida após dissolve.\"\n",
        "\n",
        "# 3) Reprojetar para WGS84 (GEE espera lon/lat em EPSG:4326 nas coords do 'region')\n",
        "gdf_wgs = gpd.GeoDataFrame(geometry=[geom_proj], crs=gdf.crs).to_crs(4326)\n",
        "\n",
        "# 4) Exportar referência em GeoJSON (WGS84)\n",
        "ref_dir = (INT_DIR / \"boundaries\"); ref_dir.mkdir(parents=True, exist_ok=True)\n",
        "ref_geojson_fp = ref_dir / \"pantanal_boundary_wgs84.geojson\"\n",
        "gdf_wgs.to_file(ref_geojson_fp, driver=\"GeoJSON\")\n",
        "print(\"✔ Boundary WGS84 salvo em:\", ref_geojson_fp)\n",
        "\n",
        "# 5) Construir ee.Geometry (aceita MultiPolygon também)\n",
        "geojson = json.loads(gdf_wgs.to_json())\n",
        "features = geojson[\"features\"]\n",
        "assert features, \"GeoJSON sem features após reprojeção.\"\n",
        "\n",
        "# Garante MultiPolygon/Polygon “limpo”\n",
        "def _as_geom_coords(feat_geom):\n",
        "    gtype = feat_geom.get(\"type\",\"\")\n",
        "    if gtype == \"Polygon\":\n",
        "        return [feat_geom[\"coordinates\"]]\n",
        "    elif gtype == \"MultiPolygon\":\n",
        "        return feat_geom[\"coordinates\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Tipo de geometria não suportado: {gtype}\")\n",
        "\n",
        "all_mparts = []\n",
        "for feat in features:\n",
        "    all_mparts.extend(_as_geom_coords(feat[\"geometry\"]))\n",
        "\n",
        "# Reconstrói como MultiPolygon → ee.Geometry\n",
        "if len(all_mparts) == 1:\n",
        "    pant = ee.Geometry.Polygon(all_mparts[0], proj=None, geodesic=True, evenOdd=True)\n",
        "else:\n",
        "    pant = ee.Geometry.MultiPolygon(all_mparts, proj=None, geodesic=True, evenOdd=True)\n",
        "\n",
        "# 6) Versão simplificada apenas para usar como 'region' nos exports\n",
        "#    A simplificação é feita no CRS do projeto (métrico), para tolerância em metros.\n",
        "gdf_metric = gdf_wgs.to_crs(CONFIG[\"crs_epsg\"])\n",
        "geom_metric = gdf_metric.geometry.values[0].simplify(SIMPLIFY_TOL_M, preserve_topology=True)\n",
        "geom_metric = geom_metric.buffer(0)  # reforça validade pós-simplificação\n",
        "gdf_metric_simpl = gpd.GeoDataFrame(geometry=[geom_metric], crs=CONFIG[\"crs_epsg\"]).to_crs(4326)\n",
        "\n",
        "geojson_simpl = json.loads(gdf_metric_simpl.to_json())\n",
        "parts_simpl = _as_geom_coords(geojson_simpl[\"features\"][0][\"geometry\"])\n",
        "if len(parts_simpl) == 1:\n",
        "    pant_simpl = ee.Geometry.Polygon(parts_simpl[0], proj=None, geodesic=True, evenOdd=True)\n",
        "else:\n",
        "    pant_simpl = ee.Geometry.MultiPolygon(parts_simpl, proj=None, geodesic=True, evenOdd=True)\n",
        "pant_bbox = pant_simpl.bounds(1)\n",
        "# 7) Prints de sanidade\n",
        "#    (área aproximada esférica em km², usando ee.Geometry area em m²)\n",
        "area_full_km2  = pant.area(maxError=10).getInfo() / 1e6\n",
        "area_simpl_km2 = pant_simpl.area(maxError=10).getInfo() / 1e6\n",
        "print(f\"✔ ee.Geometry criado. Área ~ full: {area_full_km2:,.1f} km² | simpl: {area_simpl_km2:,.1f} km²\")\n",
        "print(f\"✔ pant e pant_simpl prontos (tolerância {SIMPLIFY_TOL_M} m).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0ekTTRwVJr_"
      },
      "outputs": [],
      "source": [
        "# @title 3.LANDSAT — Helpers Landsat L2 (escala, máscara) + índices NDVI/EVI/NBR/MNDWI\n",
        "import ee\n",
        "\n",
        "def sr_scale(img):\n",
        "    \"\"\"\n",
        "    Aplica a escala dos produtos Landsat Collection 2 Level-2 (reflectância):\n",
        "      SR = DN * 0.0000275 - 0.2\n",
        "    Mantém QA_PIXEL/QA_RADSAT.\n",
        "    \"\"\"\n",
        "    optical = img.select('SR_B.*').multiply(0.0000275).add(-0.2)\n",
        "    qa = img.select('QA_PIXEL')\n",
        "    return img.addBands(optical, None, True).addBands(qa)\n",
        "\n",
        "def cloud_mask_l2(img):\n",
        "    \"\"\"\n",
        "    Máscara de nuvem/sombra/neve + saturação radiométrica.\n",
        "    Bits em QA_PIXEL (C2 L2):\n",
        "      3: Cloud, 4: Shadow, 5: Snow\n",
        "    QA_RADSAT: saturação em alguma banda.\n",
        "    Além disso, restringe a faixa física após escala (~[-0.2, 1.0]).\n",
        "    \"\"\"\n",
        "    qa = img.select('QA_PIXEL')\n",
        "    cloud  = qa.bitwiseAnd(1 << 3).neq(0)\n",
        "    shadow = qa.bitwiseAnd(1 << 4).neq(0)\n",
        "    snow   = qa.bitwiseAnd(1 << 5).neq(0)\n",
        "    mask_clouds = cloud.Or(shadow).Or(snow)\n",
        "\n",
        "    # qualquer banda saturada?\n",
        "    sat_any = img.select('QA_RADSAT').reduce(ee.Reducer.max()).gt(0)\n",
        "\n",
        "    # faixa física pós-escala\n",
        "    sr = img.select('SR_B.*')\n",
        "    valid_low  = sr.reduce(ee.Reducer.min()).gt(-0.199)  # folga\n",
        "    valid_high = sr.reduce(ee.Reducer.max()).lt(1.001)\n",
        "\n",
        "    return (img\n",
        "            .updateMask(mask_clouds.Not())\n",
        "            .updateMask(sat_any.Not())\n",
        "            .updateMask(valid_low.And(valid_high)))\n",
        "\n",
        "def add_indices_for(sensor_key):\n",
        "    \"\"\"\n",
        "    Calcula NDVI, EVI, NBR e MNDWI com mapeamento de bandas por sensor.\n",
        "    Saídas clampadas a intervalos físicos para evitar estouros mais à frente.\n",
        "    \"\"\"\n",
        "    def _fn(img):\n",
        "        if sensor_key in (\"L5_SR\", \"L7_SR\"):\n",
        "            b = {'BLUE':'SR_B1','GREEN':'SR_B2','RED':'SR_B3','NIR':'SR_B4','SWIR1':'SR_B5','SWIR2':'SR_B7'}\n",
        "        else:  # L8_SR, L9_SR\n",
        "            b = {'BLUE':'SR_B2','GREEN':'SR_B3','RED':'SR_B4','NIR':'SR_B5','SWIR1':'SR_B6','SWIR2':'SR_B7'}\n",
        "\n",
        "        nir   = img.select(b['NIR'])\n",
        "        red   = img.select(b['RED'])\n",
        "        blue  = img.select(b['BLUE'])\n",
        "        swir1 = img.select(b['SWIR1'])\n",
        "        swir2 = img.select(b['SWIR2'])\n",
        "\n",
        "        # NDVI\n",
        "        ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n",
        "        # EVI (com denominador protegido)\n",
        "        den  = nir.add(red.multiply(6)).subtract(blue.multiply(7.5)).add(1)\n",
        "        evi  = nir.subtract(red).multiply(2.5).divide(den.max(0.05)).rename('EVI')\n",
        "        # NBR\n",
        "        nbr  = nir.subtract(swir2).divide(nir.add(swir2)).rename('NBR')\n",
        "        # MNDWI (usando GREEN e SWIR1)\n",
        "        mndwi = img.expression('(g - s1) / (g + s1)', {'g': img.select(b['GREEN']), 's1': swir1}).rename('MNDWI')\n",
        "\n",
        "        # clamp físico (evita estouro ao quantizar ×10000 depois)\n",
        "        ndvi  = ndvi.max(-1).min(1)\n",
        "        evi   = evi.max(-1.5).min(1.5)\n",
        "        nbr   = nbr.max(-1).min(1)\n",
        "        mndwi = mndwi.max(-1).min(1)\n",
        "\n",
        "        return img.addBands([ndvi, evi, nbr, mndwi], overwrite=True)\n",
        "    return _fn\n",
        "\n",
        "def landsat_ic(sensor_key):\n",
        "    \"\"\"\n",
        "    Retorna a ImageCollection Landsat C2 L2 do sensor, já com:\n",
        "      - escala L2 aplicada\n",
        "      - máscara de nuvem/sombra/saturação/faixa\n",
        "      - bandas de índices NDVI, EVI, NBR, MNDWI calculadas\n",
        "    \"\"\"\n",
        "    coll_id = CONFIG[\"ee_assets\"][\"landsat_collections\"][sensor_key]\n",
        "    coll = ee.ImageCollection(coll_id)\n",
        "    return (coll\n",
        "            .map(sr_scale)\n",
        "            .map(cloud_mask_l2)\n",
        "            .map(add_indices_for(sensor_key)))\n",
        "\n",
        "print(\"✔ Célula 3.LANDSAT pronta: sr_scale, cloud_mask_l2, add_indices_for, landsat_ic.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sarsPQ31N4PM"
      },
      "outputs": [],
      "source": [
        "# @title Célula 4 — Compósito 30 m (estrito) + métricas 300 m (inclui MNDWI/dNBR/RdNBR)\n",
        "import ee\n",
        "\n",
        "def ensure_default_proj(img, scale_m=None):\n",
        "    \"\"\"Garante projeção default antes de reduceResolution.\"\"\"\n",
        "    if scale_m is None:\n",
        "        scale_m = CONFIG['optical_pixel_m']  # 30 m\n",
        "    proj = ee.Projection(f\"EPSG:{CONFIG['crs_epsg']}\").atScale(scale_m)\n",
        "    return img.setDefaultProjection(proj)\n",
        "\n",
        "def build_comp_for_export_strict(yyyymm: str, region=None) -> ee.Image:\n",
        "    \"\"\"\n",
        "    Igual à versão original, mas filtra e clippa logo no início para o 'region'\n",
        "    (tile). Isso reduz muito o volume de dados e evita OOM.\n",
        "    \"\"\"\n",
        "    if region is None:\n",
        "        region = pant  # retrocompatível\n",
        "\n",
        "    start, end = period_for_yyyymm(yyyymm)\n",
        "\n",
        "    # Filtra por tile (region) — MUITO importante para performance\n",
        "    ic = (\n",
        "        landsat_ic('L5_SR').filterDate(start, end).filterBounds(region)\n",
        "        .merge(landsat_ic('L7_SR').filterDate(start, end).filterBounds(region))\n",
        "        .merge(landsat_ic('L8_SR').filterDate(start, end).filterBounds(region))\n",
        "        .merge(landsat_ic('L9_SR').filterDate(start, end).filterBounds(region))\n",
        "        .map(lambda im: im.select(['NDVI','EVI','NBR','MNDWI']).clip(region))\n",
        "    )\n",
        "\n",
        "    comp = ic.reduce(ee.Reducer.median()).rename(['NDVI','EVI','NBR','MNDWI']).toFloat()\n",
        "    obs  = ic.select('NDVI').count().rename('OBS')\n",
        "\n",
        "    water_keep = comp.select('MNDWI').lte(CONFIG['mask_water_threshold'])\n",
        "    valid_all  = comp.mask().reduce(ee.Reducer.min())\n",
        "    has_obs    = obs.gte(1)\n",
        "    common_mask = water_keep.And(valid_all).And(has_obs)\n",
        "\n",
        "    comp_m = comp.updateMask(common_mask).clip(region)\n",
        "    obs_m  =  obs.updateMask(common_mask).clip(region)\n",
        "    return comp_m.addBands(obs_m)\n",
        "\n",
        "\n",
        "def prev_yyyymm(yyyymm: str):\n",
        "    try:\n",
        "        i = TIME_SLICES.index(yyyymm)\n",
        "        return TIME_SLICES[i-1] if i > 0 else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def build_fire_metrics_300m(yyyymm: str, region=None) -> ee.Image:\n",
        "    \"\"\"\n",
        "    Igual ao original, porém:\n",
        "      - usa compósitos 30 m já CLIPPADOS ao tile (region)\n",
        "      - reduz para 300 m depois do clip, diminuindo MUITO a carga\n",
        "    Conteúdo (bandas/valores) permanece igual dentro do tile.\n",
        "    \"\"\"\n",
        "    if region is None:\n",
        "        region = pant\n",
        "\n",
        "    yprev = prev_yyyymm(yyyymm)\n",
        "    comp_cur_30 = ensure_default_proj(build_comp_for_export_strict(yyyymm, region), CONFIG['optical_pixel_m'])\n",
        "\n",
        "    if yprev is None:\n",
        "        idx30 = comp_cur_30.select(['NDVI','EVI','NBR','MNDWI'])\n",
        "        obs30 = comp_cur_30.select('OBS').toFloat()\n",
        "        reducer = ee.Reducer.mean()\n",
        "\n",
        "        idx_agg = (idx30\n",
        "                   .reduceResolution(reducer=reducer, maxPixels=4096)\n",
        "                   .reproject(crs=f\"EPSG:{CONFIG['crs_epsg']}\", scale=CONFIG['agg_optical_to_m'])\n",
        "                   .clip(region))\n",
        "        obs_agg = (obs30\n",
        "                   .reduceResolution(reducer=reducer, maxPixels=4096)\n",
        "                   .reproject(crs=f\"EPSG:{CONFIG['crs_epsg']}\", scale=CONFIG['agg_optical_to_m'])\n",
        "                   .clip(region))\n",
        "\n",
        "        empty = ee.Image(0).updateMask(ee.Image(0))\n",
        "        dnbr_empty  = empty.rename('dNBR')\n",
        "        rdnbr_empty = empty.rename('RdNBR')\n",
        "\n",
        "        return ee.Image.cat([\n",
        "            idx_agg.select(['NDVI','EVI','NBR','MNDWI']),\n",
        "            dnbr_empty, rdnbr_empty,\n",
        "            obs_agg.rename('OBS')\n",
        "        ]).toFloat().clip(region)\n",
        "\n",
        "    comp_pre_30 = ensure_default_proj(build_comp_for_export_strict(yprev, region), CONFIG['optical_pixel_m'])\n",
        "    nbr_pre = comp_pre_30.select('NBR')\n",
        "    nbr_pos = comp_cur_30.select('NBR')\n",
        "\n",
        "    dnbr_30  = nbr_pre.subtract(nbr_pos).rename('dNBR')\n",
        "    eps  = ee.Image.constant(0.1)\n",
        "    denom = nbr_pre.abs().sqrt().max(eps)\n",
        "    rdnbr_30 = dnbr_30.divide(denom).rename('RdNBR')\n",
        "\n",
        "    reducer = ee.Reducer.mean()\n",
        "\n",
        "    idx_agg = (comp_cur_30.select(['NDVI','EVI','NBR','MNDWI'])\n",
        "               .reduceResolution(reducer=reducer, maxPixels=4096)\n",
        "               .reproject(crs=f\"EPSG:{CONFIG['crs_epsg']}\", scale=CONFIG['agg_optical_to_m'])\n",
        "               .clip(region))\n",
        "    dnbr_agg = (dnbr_30\n",
        "                .reduceResolution(reducer=reducer, maxPixels=4096)\n",
        "                .reproject(crs=f\"EPSG:{CONFIG['crs_epsg']}\", scale=CONFIG['agg_optical_to_m'])\n",
        "                .clip(region))\n",
        "    rdnbr_agg = (rdnbr_30\n",
        "                 .reduceResolution(reducer=reducer, maxPixels=4096)\n",
        "                 .reproject(crs=f\"EPSG:{CONFIG['crs_epsg']}\", scale=CONFIG['agg_optical_to_m'])\n",
        "                 .clip(region))\n",
        "    obs_agg = (comp_cur_30.select('OBS').toFloat()\n",
        "               .reduceResolution(reducer=reducer, maxPixels=4096)\n",
        "               .reproject(crs=f\"EPSG:{CONFIG['crs_epsg']}\", scale=CONFIG['agg_optical_to_m'])\n",
        "               .clip(region))\n",
        "\n",
        "    return ee.Image.cat([\n",
        "        idx_agg.select(['NDVI','EVI','NBR','MNDWI']),\n",
        "        dnbr_agg, rdnbr_agg,\n",
        "        obs_agg.rename('OBS')\n",
        "    ]).toFloat().clip(region)\n",
        "\n",
        "\n",
        "# (opcional) smoke-test rápido:\n",
        "_test = build_comp_for_export_strict(TIME_SLICES[0])\n",
        "print(\"✔ Célula 4 pronta: build_comp_for_export_strict e build_fire_metrics_300m definidas.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElUDEcXHb-IV"
      },
      "outputs": [],
      "source": [
        "# @title  Célula 5 — Exportar óptico 300 m (rodar por ANO, com resume e re-sync) ===\n",
        "# ==========================================================\n",
        "# CÉLULA 5 — Export 300 m (por ANO e MESES selecionados)\n",
        "# ==========================================================\n",
        "# - Usa apenas os YYYYMM definidos em TIME_SLICES (subconjunto do ano)\n",
        "# - Overlap + reduce→clip (evita costuras)\n",
        "# - Grade de tiles em UTM (retângulos planos, geodesic=False)\n",
        "# - Re-sync do checkpoint com o DISCO (single/merged) antes de exportar\n",
        "# - Lança somente peças faltantes (resume via dedupe pNN)\n",
        "\n",
        "import json, time, glob, re\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import ee\n",
        "\n",
        "# ---------------- Parâmetros gerais ----------------\n",
        "COG               = False\n",
        "EXPORT_SCALE_M    = int(CONFIG['agg_optical_to_m'])   # 300 m\n",
        "NODATA_INT16      = int(CONFIG['nodata'])             # -32768\n",
        "OPT_FOLDER        = CONFIG[\"gee_drive_folder_optical\"]\n",
        "\n",
        "QUEUE_SIZE        = 2\n",
        "SLEEP_S           = 10\n",
        "OVERLAP_M         = 600        # >= 1 célula de 300 m é suficiente\n",
        "\n",
        "# ---------------- Projeções/helpers ----------------\n",
        "PROJ_UTM = ee.Projection(f\"EPSG:{CONFIG['crs_epsg']}\")\n",
        "\n",
        "try:\n",
        "    REGION_EXPORT_UTM = pant.transform(PROJ_UTM, 1).bounds(1, PROJ_UTM)\n",
        "except NameError:\n",
        "    REGION_EXPORT_UTM = pant_simpl.transform(PROJ_UTM, 1).bounds(1, PROJ_UTM)\n",
        "\n",
        "def _proj_30m():\n",
        "    return ee.Projection(f\"EPSG:{CONFIG['crs_epsg']}\").atScale(CONFIG['optical_pixel_m'])\n",
        "\n",
        "def _proj_300m():\n",
        "    return ee.Projection(f\"EPSG:{CONFIG['crs_epsg']}\").atScale(EXPORT_SCALE_M)\n",
        "\n",
        "def _reduce_to_300m(img, region):\n",
        "    img = img.setDefaultProjection(_proj_30m())\n",
        "    return (img\n",
        "            .reduceResolution(reducer=ee.Reducer.mean(), maxPixels=4096)\n",
        "            .reproject(crs=_proj_300m())\n",
        "            .clip(region))\n",
        "\n",
        "def _build_out_image_from_globals(comp_cur_30, dnbr_30, rdnbr_30, region_reduce, region_clip):\n",
        "    comp_cur_30 = comp_cur_30.setDefaultProjection(_proj_30m())\n",
        "    dnbr_30     = dnbr_30.setDefaultProjection(_proj_30m())\n",
        "    rdnbr_30    = rdnbr_30.setDefaultProjection(_proj_30m())\n",
        "\n",
        "    idx30 = comp_cur_30.select(['NDVI','EVI','NBR','MNDWI'])\n",
        "    obs30 = comp_cur_30.select('OBS').toFloat()\n",
        "\n",
        "    idx_agg   = _reduce_to_300m(idx30,   region_reduce)\n",
        "    dnbr_agg  = _reduce_to_300m(dnbr_30, region_reduce)\n",
        "    rdnbr_agg = _reduce_to_300m(rdnbr_30, region_reduce)\n",
        "    obs_agg   = _reduce_to_300m(obs30,   region_reduce)\n",
        "\n",
        "    out_float = ee.Image.cat([\n",
        "        idx_agg.select(['NDVI','EVI','NBR','MNDWI']),\n",
        "        dnbr_agg.rename('dNBR'),\n",
        "        rdnbr_agg.rename('RdNBR'),\n",
        "        obs_agg.rename('OBS')\n",
        "    ]).toFloat()\n",
        "\n",
        "    idx_names = ['NDVI','EVI','NBR','MNDWI','dNBR','RdNBR']\n",
        "    idx_i16 = out_float.select(idx_names).multiply(10000).round().toInt16()\n",
        "    obs_i16 = out_float.select('OBS').round().toInt16()\n",
        "    nod = ee.Image.constant(NODATA_INT16).toInt16()\n",
        "\n",
        "    out = idx_i16.unmask(nod).addBands(obs_i16.unmask(nod)).reproject(_proj_300m())\n",
        "    return out.clip(region_clip)\n",
        "\n",
        "# ---------------- Grade UTM ----------------\n",
        "def _make_grid(region, nx=15, ny=15):\n",
        "    reg_utm = ee.Geometry(region).transform(PROJ_UTM, 1)\n",
        "    b = reg_utm.bounds(1, PROJ_UTM)\n",
        "    coords = ee.List(b.coordinates().get(0))\n",
        "    ll = ee.List(coords.get(0)); ur = ee.List(coords.get(2))\n",
        "    xmin = ee.Number(ll.get(0)); ymin = ee.Number(ll.get(1))\n",
        "    xmax = ee.Number(ur.get(0)); ymax = ee.Number(ur.get(1))\n",
        "    dx = xmax.subtract(xmin).divide(nx); dy = ymax.subtract(ymin).divide(ny)\n",
        "    tiles=[]\n",
        "    for iy in range(ny):\n",
        "        for ix in range(nx):\n",
        "            x0 = xmin.add(dx.multiply(ix)); x1 = x0.add(dx)\n",
        "            y0 = ymin.add(dy.multiply(iy)); y1 = y0.add(dy)\n",
        "            tiles.append(ee.Geometry.Rectangle([x0,y0,x1,y1], PROJ_UTM, False))\n",
        "    return tiles\n",
        "\n",
        "# ---------------- Utilidades de Drive/estado ----------------\n",
        "ROOTS = [Path(\"/content/drive/MyDrive\"), Path(\"/content/drive/My Drive\")]\n",
        "def _glob_all(pat):\n",
        "    s=set()\n",
        "    for r in ROOTS: s |= set(glob.glob(str(r/pat)))\n",
        "    return sorted(s)\n",
        "\n",
        "def _month_has_single(ym):   # opt_YYYYMM.tif\n",
        "    return bool(_glob_all(f\"{OPT_FOLDER}/opt_{ym}.tif\"))\n",
        "\n",
        "def _month_has_merged(ym):   # ..._merged/opt_YYYYMM_merged.tif\n",
        "    return bool(_glob_all(f\"{OPT_FOLDER}_merged/opt_{ym}_merged.tif\"))\n",
        "\n",
        "def _files_for_month(ym):\n",
        "    single = _glob_all(f\"{OPT_FOLDER}/opt_{ym}.tif\")\n",
        "    merged = _glob_all(f\"{OPT_FOLDER}_merged/opt_{ym}_merged.tif\")\n",
        "    pieces = _glob_all(f\"{OPT_FOLDER}/opt_{ym}_p*.tif\")\n",
        "    return single, merged, pieces\n",
        "\n",
        "def _existing_piece_indices(ym):\n",
        "    # dedupe: reconhece pNN e ignora duplicatas com \" (1)\" etc.\n",
        "    rx = re.compile(rf\"^opt_{ym}_p(\\d+)(?: \\(\\d+\\))?\\.tif$\", re.IGNORECASE)\n",
        "    idx=set()\n",
        "    for fp in _glob_all(f\"{OPT_FOLDER}/opt_{ym}_p*.tif\"):\n",
        "        m = rx.match(Path(fp).name)\n",
        "        if m: idx.add(int(m.group(1)))\n",
        "    return idx\n",
        "\n",
        "def _unique_piece_count(ym):\n",
        "    return len(_existing_piece_indices(ym))\n",
        "\n",
        "# ---------- Dependências mínimas de outras células ----------\n",
        "try:\n",
        "    prev_yyyymm\n",
        "except NameError:\n",
        "    def prev_yyyymm(yyyymm: str):\n",
        "        try:\n",
        "            i = TIME_SLICES.index(yyyymm)\n",
        "            return TIME_SLICES[i-1] if i > 0 else None\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "try:\n",
        "    ensure_default_proj\n",
        "except NameError:\n",
        "    def ensure_default_proj(img, scale_m=None):\n",
        "        if scale_m is None:\n",
        "            scale_m = CONFIG['optical_pixel_m']  # 30 m\n",
        "        proj = ee.Projection(f\"EPSG:{CONFIG['crs_epsg']}\").atScale(scale_m)\n",
        "        return img.setDefaultProjection(proj)\n",
        "\n",
        "try:\n",
        "    build_comp_for_export_strict\n",
        "except NameError:\n",
        "    raise RuntimeError(\"Execute antes as células 2, 3 e 4 (GEE/boundary/LANDSAT/compósitos).\")\n",
        "\n",
        "# ---------- Checkpoint ÓPTICO por ANO ----------\n",
        "CKP_OPT = LOG_DIR / f\"export_optical_checkpoint_{CKP_SUFFIX}.json\"\n",
        "state_opt = json.load(open(CKP_OPT)) if CKP_OPT.exists() else {\"done\": {}}\n",
        "def _save_ckp_opt(): json.dump(state_opt, open(CKP_OPT, \"w\"))\n",
        "\n",
        "EXPECTED_PIECES_DEFAULT = 225  # 15x15\n",
        "\n",
        "def _build_out_image_whole_region(yyyymm: str, region):\n",
        "    nx, ny = 15, 15\n",
        "    tiles  = _make_grid(region, nx=nx, ny=ny)\n",
        "    existing = _existing_piece_indices(yyyymm)\n",
        "    launched = 0\n",
        "    yprev = prev_yyyymm(yyyymm)\n",
        "\n",
        "    for k, q in enumerate(tiles):\n",
        "        if k in existing:\n",
        "            continue  # peça já existe (mesmo que duplicada, dedupe é no merge)\n",
        "\n",
        "        q_pad = ee.Geometry(q).buffer(OVERLAP_M)\n",
        "\n",
        "        comp_cur_30_q = ensure_default_proj(\n",
        "            build_comp_for_export_strict(yyyymm, region=q_pad),\n",
        "            CONFIG['optical_pixel_m']\n",
        "        ).setDefaultProjection(_proj_30m())\n",
        "\n",
        "        if yprev:\n",
        "            comp_pre_30_q = ensure_default_proj(\n",
        "                build_comp_for_export_strict(yprev, region=q_pad),\n",
        "                CONFIG['optical_pixel_m']\n",
        "            ).setDefaultProjection(_proj_30m())\n",
        "            dnbr_30_q  = comp_pre_30_q.select('NBR').subtract(comp_cur_30_q.select('NBR')).rename('dNBR')\n",
        "            denom_q    = comp_pre_30_q.select('NBR').abs().sqrt().max(ee.Image.constant(0.1))\n",
        "            rdnbr_30_q = dnbr_30_q.divide(denom_q).rename('RdNBR')\n",
        "        else:\n",
        "            empty_q = ee.Image(0).updateMask(ee.Image(0)).setDefaultProjection(_proj_30m())\n",
        "            dnbr_30_q, rdnbr_30_q = empty_q.rename('dNBR'), empty_q.rename('RdNBR')\n",
        "\n",
        "        out_q = _build_out_image_from_globals(comp_cur_30_q, dnbr_30_q, rdnbr_30_q, q_pad, q)\n",
        "\n",
        "        desc = f\"opt_{yyyymm}_p{k:02d}\"\n",
        "        task = ee.batch.Export.image.toDrive(\n",
        "            image = out_q,\n",
        "            description   = desc,\n",
        "            folder        = OPT_FOLDER,\n",
        "            fileNamePrefix= desc,\n",
        "            region        = q,\n",
        "            crs           = f\"EPSG:{CONFIG['crs_epsg']}\",\n",
        "            scale         = EXPORT_SCALE_M,\n",
        "            maxPixels     = 1e13,\n",
        "            fileFormat    = 'GeoTIFF',\n",
        "            formatOptions = {'noData': NODATA_INT16}\n",
        "        )\n",
        "        task.start()\n",
        "        launched += 1\n",
        "\n",
        "    log(f\"[{yyyymm}] tiles lançados agora: {launched} (faltantes).\")\n",
        "    return None\n",
        "\n",
        "def _launch_export_month(yyyymm: str, region):\n",
        "    # se já existe single ou merged → marca done e pula\n",
        "    if _month_has_single(yyyymm) or _month_has_merged(yyyymm):\n",
        "        state_opt[\"done\"][yyyymm] = True\n",
        "        return None\n",
        "    return _build_out_image_whole_region(yyyymm, region)\n",
        "\n",
        "# ---------------- Scheduler (usa APENAS TIME_SLICES) ----------------\n",
        "# Em vez de gerar meses automaticamente, seguimos estritamente o subconjunto escolhido.\n",
        "months = TIME_SLICES\n",
        "\n",
        "# (1) Re-sync do checkpoint: done=True somente se existe single OU merged no disco\n",
        "changed=0\n",
        "for ym in months:\n",
        "    single, merged, _ = _files_for_month(ym)\n",
        "    new_done = bool(single or merged)\n",
        "    if state_opt[\"done\"].get(ym, False) != new_done:\n",
        "        state_opt[\"done\"][ym] = new_done\n",
        "        changed += 1\n",
        "if changed:\n",
        "    _save_ckp_opt(); print(f\"✔ checkpoint re-sincronizado ({changed} updates).\")\n",
        "else:\n",
        "    print(f\"✔ checkpoint já consistente.\")\n",
        "\n",
        "# (2) Diagnóstico: meses faltando (sem single/merged) e quantas peças únicas tem\n",
        "faltando=[]\n",
        "for ym in months:\n",
        "    if not state_opt[\"done\"].get(ym, False):\n",
        "        nuniq = _unique_piece_count(ym)\n",
        "        faltando.append((ym, nuniq, EXPECTED_PIECES_DEFAULT - nuniq))\n",
        "\n",
        "if faltando:\n",
        "    print(\"→ Meses faltando (únicas / faltam):\")\n",
        "    for ym, nuniq, miss in faltando:\n",
        "        print(f\"   {ym}: {nuniq} / {miss}\")\n",
        "else:\n",
        "    print(\"→ Nenhum mês faltando (todos com single/merged).\")\n",
        "\n",
        "# (3) Exporta SOMENTE os que estão faltando (resume garante que só peças ausentes são lançadas)\n",
        "to_run = [ym for ym,_n,_miss in faltando]\n",
        "for ym in to_run:\n",
        "    _launch_export_month(ym, REGION_EXPORT_UTM)\n",
        "\n",
        "print(\"✔ Exports disparados para:\", months)\n",
        "print(f\"✔ Checkpoint ÓPTICO em: {CKP_OPT}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fu_Wc9dkW17H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlJpS2h2ohdcLYuuvoDz9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
